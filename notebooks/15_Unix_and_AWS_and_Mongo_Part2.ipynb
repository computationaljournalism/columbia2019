{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unix, Mongo and a Computer in the Cloud (Part 2) ‚òÅÔ∏è\n",
    "-------------------------------------------------\n",
    "\n",
    "This notebook is a continuation of the previous one and we'll pick up where we left off (somewhere in Ohio). You now have some basic UNIX commands under your belt. As Mark says, if you are stranded on a deserted island üèñÔ∏è and need to rebuild all of humanity - your terminal and some UNIX commands will help!\n",
    "\n",
    "Next up, we're going to learn how to set up a database on our cloud server, store some tweets in our database and then query the database remotely (from our notebook!). Let's get started.\n",
    "\n",
    "1. twarc - a comand-line based Twitter API\n",
    "2. Mongo database - where we can store our data in the cloud\n",
    "3. How to talk to our Mongo database from the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "__ \n",
    "(__) \n",
    " ||.__ \n",
    " ||`\\##`--.__ \n",
    " ||  `\\######`--.__  \n",
    " ||    `\\##########`--.__ \n",
    " ||      `\\##############`--.__ \n",
    " ||     *  `\\'#################`--.__ \n",
    " ||          `\\  '###################`--.__ \n",
    " || *          `\\     '####################`--.__ \n",
    " ||              `\\       '######################`--.__ \n",
    " ||                `\\            '#####################`--.__ \n",
    " ||           *      `\\                '#####################`-. \n",
    " ||      *         *   `\\                    '#############_.-' \n",
    " ||       .''''''''.     `\\                        '####.-' \n",
    " ||  *   ' .######. '.     `\\                   __.-'~~ \n",
    " ||    .` .########. `.      `\\##############.-' \n",
    " ||   .' .##########. `.    *  `\\#########.-' \n",
    " || * :  ############  : *     * >#######< \n",
    " ||   `. '##########' .'    *   /##########`-._ \n",
    " ||    '. '########' .'       /############### `--._ \n",
    " ||  *  '. '######' .'      /'                      `--._ \n",
    " ||       `'.......'      /'                        .####'--._ \n",
    " ||      *          *   /'                    '############## `-. \n",
    " ||           *       /'                .###################.-'~ \n",
    " ||                 /'           .####################.--'~~ \n",
    " ||               /'       .#####################.--'~~ \n",
    " ||  *          /'    .####################.--'~~ \n",
    " ||           /' .###################.--'~~ \n",
    " ||      *  /'#################.--'~~ \n",
    " ||       /##############.--'~~ \n",
    " ||     /##########.--'~~ \n",
    " ||   /##JGS##.--'~~ \n",
    " || /##.--'~~ \n",
    " ||'~~~ \n",
    " || \n",
    " ||  \n",
    " ||  \n",
    " ||  \n",
    " \n",
    " Ohio State Flag\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Go Back to Our Computer in the Cloud\n",
    "\n",
    "**Open a new Terminal window.**\n",
    "\n",
    "Let's `ssh` back to our EC2 Instance that we set up two weeks ago. If you need a refresher on how to connect to it, log back in to the AWS EC2 site, click on the \"x Running Instances\" link to find your list of EC2 instances. Make sure your instance is running. If it's not running, click on Actions --> \"Instance State\" --> Start. Once it's running, highlight your instance in the table and click on the **\"Connect\"** button. Towards the bottom of the \"Connect\" info window, it will give you the `ssh` command you need to run in your own terminal window. **REMEMBER** you need to run this command from the folder/directory where your `.pem` file resides.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ssh -i (yourkey.pem) ec2-user@(your machine)`\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-ami/2017.09-release-notes/\n",
    "6 package(s) needed for security, out of 8 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "[ec2-user@ip-172-30-0-108 ~]$\n",
    "```\n",
    "<br><br>\n",
    "You should see the comforting `$` of our EC2 instance.\n",
    "```\n",
    "         __\n",
    "        /  \\\n",
    "       / ..|\\\n",
    "      (_\\  |_)\n",
    "      /  \\@'\n",
    "     /     \\\n",
    " _  /  `   |\n",
    "\\\\/  \\  | _\\\n",
    " \\   /_ || \\\\_\n",
    "  \\____)|_) \\_)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter in the Cloud**\n",
    "\n",
    "To monitor Twitter remotely, we can use an application called twarc. It is a command line tool for archiving tweets. It handles all the rate limits and lets you worry about what you're going to do with the data once it's puddledup. First, using your terminal window that is logged into the EC2 t2.micro computer, install twarc. It's a Python application so...\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo pip install twarc`\n",
    "\n",
    "Ah, `sudo`. That's a command that basically promotes you to administrator while you install twarc. Think about your laptop. When you install software, you have to type in a password because you need to have super powers to put files on certain parts of the computer. Your guests, for example, probably don't have this ability. \n",
    "\n",
    "Once you have installed twarc, you should configure it with your keys. Have them ready from Twitter ([go to apps.twitter.com](https://apps.twitter.com/)) and type\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`twarc configure`\n",
    "\n",
    "OK that done, we can now start monitoring Twitter! Here's a simple command to get all of realDonaldTrump's tweets:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`twarc timeline realDonaldTrump`\n",
    "\n",
    "OK that had a lot of stuff streaming by. Essentially, you received all of realDonaldTrump's tweets, up to the rate limit. We didn't ask to do anything with them so they just printed out. twarc has a lot of great features that let you do things like follow people and watch their tweets in real time. According to [https://tweeterid.com/](https://tweeterid.com/), realDonaldTrump as a twitter id of 25073877. Here's how we follow this account.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`twarc filter --follow  25073877`\n",
    "\n",
    "And now the printout is slower, but it is meant to be printing both realDonaldTrump's tweets and retweets ([and people replying and retweeting him](https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/basic-stream-parameters)). You end this parade by entering Cntl-C to kill the twarc job.\n",
    "\n",
    "twarc is quite useful. Here is [detailed documentation](https://github.com/DocNow/twarc). I'd advise using it where you can.\n",
    "\n",
    "**Storage: Moving files back and forth into the cloud**\n",
    "\n",
    "Now, rather than have the data stream by, we could capture it in a file. Recall our \"redirect\" that dumps output into a file. Let's look at something possibly a little more interesting than Trump's tweets - let's search for tweets containing `MuellerReport` in the past week. Btw, the `-filter:nativeretweets` is a way to tell Twitter that we want to filter out native retweets. In the `twarc search` command, you can add [advanced Twitter search operators](http://followthehashtag.com/help/hidden-twitter-search-operators-extra-power-followthehashtag/) to help filter your search results. Here we store tweets that contain `MuellerReport` in a file called `muellerreport.json`. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`twarc search \"MuellerReport since:2019-03-22 until:2019-03-27 -filter:nativeretweets\" > muellerreport.json`\n",
    "\n",
    "After running this for a minute or so, you'll notice that it doesn't return our prompt back to us. This is because the `twarc search` command, will call Twitter's search API until it runs in to rate limits. When twarc runs in to rate limits, it \"sleeps\" until the rate limits are up and then continues on with its work. To stop twarc from running, enter Cntrl-C to kill it.\n",
    "\n",
    "Let's take a look at how many tweets we have in our file after our search for `MuellerReport` by typing:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`wc -l muellerreport.json`\n",
    "\n",
    "You should have something around 16K tweets.\n",
    "\n",
    "Now, to make use of it, let's copy it from our cloud computer back to our desktop. So type \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`exit`\n",
    "\n",
    "and you should end up with a prompt that looks more like your laptop where you started. Now, hit the \"up arrow\" key on your keyboard while you are in the terminal window. This will recall your last command. You can then alter it to the following (keeping `yourkey` and `yourmachine` as they are in your terminal window. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`scp -i (yourkey.pem) ec2-user@(your machine):muellerreport.json .`\n",
    "\n",
    "This command is \"secure copy\" -- it uses your credentials or key to move the file `muellerreport.json` from your amazon computer to your laptop. If you want to copy some other file `abc.txt` to the cloud machine you would do this.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`scp -i (yourkey.pem) abc.txt ec2-user@(your machine).com:`\n",
    "\n",
    "So the syntax is \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`scp -i (yourkey.pem) from_file to_file`\n",
    "\n",
    "... make sure you see this by comparing the two lines above. Now, we can read that file in (maybe you have to put `muellerreport.json` into the folder where your notebook is located)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "\n",
    "# read in the tweets as strings from the file - one line per tweet\n",
    "tweetstrings = open('muellerreport.json').readlines()\n",
    "\n",
    "# for the first 20 strings, load them into python objects (dictionaries)\n",
    "# and print out the text of the tweet\n",
    "\n",
    "for t in tweetstrings[:20]:\n",
    "    tweet = loads(t)\n",
    "    print(tweet[\"full_text\"])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "            ,/A\\,\n",
    "          .//`_`\\\\,\n",
    "        ,//`____-`\\\\,\n",
    "      ,//`[_ROVER_]`\\\\,\n",
    "    ,//`=  ==  __-  _`\\\\,\n",
    "   //|__=  __- == _  __|\\\\\n",
    "   ` |  __ .-----.  _  | `\n",
    "     | - _/       \\-   |\n",
    "     |__  | .-\"-. | __=|\n",
    "     |  _=|/)   (\\|    |\n",
    "     |-__ (/ a a \\) -__|\n",
    "jgs  |___ /`\\_Y_/`\\____|\n",
    "          \\)8===8(/\n",
    "```\n",
    "\n",
    "**Storage: Installing a Mongo database**\n",
    "\n",
    "That's cool but we can do way way better. Let's go back to your computer in the Amazon cloud and install a database. We will use something called MongoDB (Mongo from hu*mongo*us.). You can [read about the project here.](https://www.mongodb.com/). It is an example of a new-ish breed of data bases that have emerged. They are called NoSQL (for non-SQL or \"not only\" SQL) and signal a break from the relational model (which, weirdly, we will come back to). According to the Mongo site, some examples of this new breed include\n",
    "\n",
    "* **Document databases** pair each key with a complex data structure known as a document. Documents can contain many different key-value pairs, or key-array pairs, or even nested documents.\n",
    "* **Graph stores** are used to store information about networks of data, such as social connections. Graph stores include Neo4J and Giraph.\n",
    "* **Key-value stores** are the simplest NoSQL databases. Every single item in the database is stored as an attribute name (or 'key'), together with its value. Examples of key-value stores are Riak and Berkeley DB. Some key-value stores, such as Redis, allow each value to have a type, such as 'integer', which adds functionality.\n",
    "* **Wide-column stores** such as Cassandra and HBase are optimized for queries over large datasets, and store columns of data together, instead of rows.\n",
    "\n",
    "Mongo is a document database, where the documents are represented by JSON strings. This kind of flexibility is perfect for our Twitter data, as a tweet is just a JSON object. To install Mongo on our cloud machine, `ssh` over there and let's do the following. Oh we have [taken these instructions mainly from here.](https://github.com/SIB-Colombia/dataportal-explorer/wiki/How-to-install-node-and-mongodb-on-Amazon-EC2)\n",
    "\n",
    "1. Secure shell over to your Amazon machine using the `ssh` command from above.\n",
    "2. The version of `pip` for Linux (or a version) is something called `yum`. It stands for \"Yellow Dog Updater, Modified\". It was the package manager for a version of Linux called Yellow Dog Linux (which was an early UNIX OS that ran on a Mac!). Our first command will be to update `yum` itself. First, making sure all its packages are current.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo yum check-update`<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo yum update`\n",
    "<br><br> Then, `yum` needs a database of projects to look through and our next commands will be to update that list. Don't worry too much about this, it's just adding a \"repo\" to the places where `yum` looks  for code to install.  \n",
    "<br>\n",
    "`echo \"[mongodb-org-4.0]\n",
    "name=MongoDB Repository\n",
    "baseurl=https://repo.mongodb.org/yum/amazon/2013.03/mongodb-org/4.0/x86_64/\n",
    "gpgcheck=1\n",
    "enabled=1\n",
    "gpgkey=https://www.mongodb.org/static/pgp/server-4.0.asc\" |\n",
    "sudo tee -a /etc/yum.repos.d/mongodb-org-4.0.repo`\n",
    "<br><br>\n",
    "3. Next, install MongoDB. It's just like using `pip` except that we have to `sudo` for administrator powers and then use `yum` for a Linux app. \n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo yum install -y mongodb-org`\n",
    "<br><br>\n",
    "4. We are using the /var/lib/mongo folder to save our database data, a log file and so on. These defaults are fine.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo mkdir /var/lib/mongo/data`\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo mkdir /var/lib/mongo/log`\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo mkdir /var/lib/mongo/journal`\n",
    "<br><br>\n",
    "5. Set the storage items (data, log, journal) to be owned by the user (mongod) and group (mongod) that MongoDB will be starting under:\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo chown mongod:mongod /var/lib/mongo/data`\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo chown mongod:mongod /var/lib/mongo/log`\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo chown mongod:mongod /var/lib/mongo/journal`\n",
    "<br><br>\n",
    "6. Set the MongoDB service to start at \"boot\" (if you ever have to reboot your machine) and activate Mongo!\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo chkconfig mongod on`\n",
    "<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo /etc/init.d/mongod start`\n",
    "<br><br>\n",
    "7. Have a look around! MongoDB has a shell (everything does!) that you can use to look at data, etc. There's not much to do now except maybe create a new database and a user who can read and write into the database.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`mongo`\n",
    "<br><br>\n",
    "Not much to do just yet. I mean you can ask for help, and maybe `show databases`. So let's add some data. But first, <br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`quit()` \n",
    "<br><br>\n",
    "out of here. \n",
    "\n",
    "```\n",
    " __/ / \\\n",
    "|    |/\\\n",
    "|_--\\   \\              /-\n",
    "     \\   \\-___________/ /\n",
    "      \\                :\n",
    "      |                :\n",
    "      |       ___ \\    )\n",
    "       \\|  __/     \\  )\n",
    "        | /         \\  \\\n",
    "        |l           ( l\n",
    "        |l            ll\n",
    "        |l            |l\n",
    "       / l           / l\n",
    "       --/           --\n",
    "```\n",
    "\n",
    "**Loading data into Mongo**\n",
    "\n",
    "Now, let's store data. We'll take the MuellerReport tweets and dump them into a database. The instructions [are given here](https://gist.github.com/edsu/ac57715ac0a2fec3bc64).\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`twarc search \"MuellerReport since:2019-03-22 until:2019-03-27 -filter:nativeretweets\" | mongoimport --db tweets --collection muellerreport` \n",
    "<br><br>\n",
    "This command uses twarc, searches Twitter for tweets containing MuellerReport and then pipes the output (pipes!) into  a command `mongoimport` to bring the data into our database. The database is called `tweets` and the particular collection of documents is called `muellerreport`. \n",
    "\n",
    "Think of this structure as having one database per project and then multiple collections of documents (JSON data) in each database.\n",
    "\n",
    "Again, the `twarc search` command will run forever, so you'll need to enter Cntrl-C after 30 seconds or a minute to kill the command. \n",
    "\n",
    "To see what we've done, let's get into Mongo \n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`mongo`\n",
    "<br><br>\n",
    "and then look at the databases\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`show databases`\n",
    "<br><br>\n",
    "to see your `tweets` and then \n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`use tweets`\n",
    "<br><br>\n",
    "to switch to that database. We can then see what collections are available in this database.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`show collections`\n",
    "<br><br>\n",
    "And we can see what's there. Maybe we count the tweets we've recorded in each collection.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`db.muellerreport.count()`\n",
    "<br>\n",
    "\n",
    "The structure of this command in the Mongo shell is `db.collectionname.action`. We can do things like find all the tweets that mention `muellerreport` that were retweeted over 1,000 times:\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`db.muellerreport.find({retweet_count:{$gt:1000}})`\n",
    "\n",
    "This gives us the entire tweet object for each tweet that was RT'd over 1,000 times. We can modify our `find` command to have it return only the retweet_count, and the text of the tweet (as opposed to the whole thing). Here is the code:\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`db.muellerreport.find({retweet_count:{$gt:1000}},{retweet_count:1,full_text:1})`\n",
    "\n",
    "In general, the `find()` command searches for JSON documents and uses a dictionary syntax to find them. Here we searched for the `retweet_count` field, looking for those well retweeted tweets. \\$gt and \\$lt are ways to specify ranges. The second argument of `find()` gives a dictionary that tells you what data to keep. The value 1 means keep.\n",
    "\n",
    "The Mongo shell is really powerful. The Mongo site [has great documentation on `find()` and other commands](https://docs.mongodb.com/manual/reference/method/db.collection.find/). Now, we are often going to access a database from the comfort of some other computing environment. In this case, Python. \n",
    "\n",
    "**NOTE** If the `count()` command from above 0 it's because we tried to run our `twarc search` command and hit Twitter's API rate limites. You can type `quit()` to quit Mongo and then you can import the tweets stored in our muellerreport.json file. by running the following command:\n",
    "\n",
    "`cat muellerreport.json | mongoimport --db tweets --collection muellerreport`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Before we move on, let's set up a few users in our database to allow us to administer it (later) and access it remotely. First, we'll create our admin user. Please change the password here to something you can use later. Copy the following lines in to mongo:\n",
    "<pre>\n",
    "use admin\n",
    "db.createUser(\n",
    "  {\n",
    "    user: \"admin\",\n",
    "    pwd: \"SomeStrongPasswordHere4JustYou\",\n",
    "    roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" }, \"readWriteAnyDatabase\" ]\n",
    "  }\n",
    ")\n",
    "</pre>\n",
    "\n",
    "2. To prepare our database for remote access, we'll set up a user (with a password). In mongo you can copy the following:\n",
    "<pre>\n",
    "use tweets\n",
    "db.createUser({\n",
    "  user: 'journalist',\n",
    "  pwd: 'secret',\n",
    "  roles: [{ role: 'readWrite', db:'tweets'}]\n",
    "})\n",
    "</pre>\n",
    "and then get out\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;quit()\n",
    "<br><br>\n",
    "\n",
    "3. Next, we want to open up Mongo to talk to the outside world. This means changing its configuration file. Here we comment out one command and remove the comment from another. We are using an old old UNIX command called Sed for the Stream Editor.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo sed -i 's/bindIp.*/bindIp: 0.0.0.0/' /etc/mongod.conf`\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo sed -i 's/^#security/security/' /etc/mongod.conf `\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo sed -i \"/^security/a  \\ \\ \\ authorization: 'enabled'\" /etc/mongod.conf`\n",
    "<br><br>\n",
    "4. Return to your EC2 Console and click on the instance in the upper pane of the console. Below you will see details about your computer and scroll down to \"Security Groups\". It should probably be \"launch-wizard-1\". Click on it and look at its security rules. Click on the \"Inbound\" tab. You see port 22 on the machine is open for `ssh` communication (that includes the secure shell and secure copy). Click \"Edit\" and then \"Add Rule\". You will want to select \"Custom TCP Rule\" (the default) and then Port 27017 and the access IP of 0.0.0.0/0, meaning every computer can connect. If there was just one IP address that needed your data, you could put it there instead. Hit \"Save\" and go back to your Terminal logged into the Amazon computer.\n",
    "5. On the Amazon computer restart Mongo with its new user and new network aware self.\n",
    "<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`sudo service mongod restart`\n",
    "<br><br>\n",
    "\n",
    "And there we are. Mongo is up and running and we can now talk to it. Let's! To do this in Python, we need to install PyMongo. Yay!\n",
    "\n",
    "```\n",
    "            __\n",
    "(\\,--------'()'--o\n",
    " (_    ___    /~\"\n",
    "  (_)_)  (_)_)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python and Mongo - PyMongo, of course!**\n",
    "\n",
    "PyMongo lets us access a database from the comfort of our notebook. There are a few tutorials online, but [the basic documentation is here.](http://api.mongodb.com/python/current/tutorial.html) For the most part, the structure and commands are similar to those in Mongo itself. The documents stored in a Mongo database can be nested structures and, as we have seen, we often do a little work to get them into regular table format. \n",
    "\n",
    "Before we go too far, let's install PyMongo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to import the MongoClient function. It takes a specification for the location of a Mongo database and returns a client object. Working with the client object  is a bit like typing into the `mongo` shell as we did above. Here we create the client and then access the \"tweets\" database.\n",
    "\n",
    "**NOTE** you will need to put the IP address of your Amazon EC2 instance in the code below where we connect to our Mongo database. Look back at the EC2 console web page and find the `IPv4 Public IP` for our instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://journalist:secret@your-ec2-instance-name-goes-here:27017/tweets\")\n",
    "type(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression above matches the  Mongo shell expression. We can also use something a bit more Python inspired  and ask for the \"tweets\" database using subset notation. The expression above is equivalent to the the one  below. both return a link to a database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client[\"tweets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can ask for the different `collection_names()` that we have loaded. Remember that a document database consists of different collections of documents. In our case a document is a tweet and our collections refer to the Mueller Report tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling our simple Mongo commands, here  are the number  of documents (tweets) in each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[\"muellerreport\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we create a variable `mueller` that represents the `muellerreport` collection of tweets. This keeps us from continually typing out the full expression. From here we can look at one  tweet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mueller = db[\"muellerreport\"]\n",
    "mueller.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or maybe iterate through several that match a search criterion. That's one of the reasons to have a database in the first place -- we can make searching very fast. In the expression below, we form a search for all the tweets with where the language is \"undefined\". A search is literally expressed as another document. Here's our query.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`{\"lang\": \"und\"}`\n",
    "\n",
    "Let's see how many tweets match this criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mueller.find({\"lang\": \"und\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a regular expression to find a pattern in the source and not just a literal match. Here we find how many people tweeted from an iPhone. For this, we make use of an operator to specify the documents of interest.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`{\"source\": {\"$regex\":\"iphone\"}}`\n",
    "\n",
    "Let's see how many there are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mueller.find({\"source\": {\"$regex\":\"(iphone)\"}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the expression below, we form a search for all the tweets with a `retweet_count` larger than 1000. There are special operators $gt and \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`{\"retweet_count\":{\"$gt\":1000}}`\n",
    "\n",
    "And count..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mueller.find({\"retweet_count\":{\"$gt\":1000}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    ___\n",
    " __/_  `.  .-\"\"\"-.\n",
    " \\_,` | \\-'  /   )`-')\n",
    "  \"\") `\"`    \\  ((`\"`\n",
    " ___Y  ,    .'7 /|\n",
    "(_,___/...-` (_/_/ sk\n",
    "```\n",
    "\n",
    "Rather than just counting, we can iterate through the set to display our results. Here we search for tweets with a retweet count over 1,000 and we only keep the fields `text`, `retweet_count` and `user.screen_name` (the \".\" is how we index into an embedded document, `screen_name` being a key to the `user` dictionary of the tweet). The notation in the second dictionary assigns a value of `True` to a key if you want to keep the variable with that name and it assigns a `False` otherwise. (You will also see 1 and 0 instead -- remember `True` reduces to 1 and `False` to 0.) This is called **a projection**. The first two arguments to `find()` are `filter=` and `projection=`. \n",
    "\n",
    "Here we are leaving out Mongo's `_id` variable as it's an internal Mongo index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in mueller.find({\"retweet_count\":{\"$gt\":1000}},{\"full_text\":True,\"retweet_count\":True,\"user.screen_name\":True,\"_id\":False}):\n",
    "    print(tweet)\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database can do quite a bit of work for you before you request  any data. You can, for example, look at all the tweets, ordered by retweet count, but maybe with the largest retweet count first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import ASCENDING, DESCENDING\n",
    "\n",
    "for tweet in mueller.find().sort(\"retweet_count\",DESCENDING).limit(20):\n",
    "    print(tweet[\"retweet_count\"],tweet[\"full_text\"])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this lets us form subsets of data and creates a \"cursor\" that lets us walk through the data, processing things as we like. We can also take the data directly into a, you guessed it, Pandas data frame. We'll dive in to more of this in the coming lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "We now have a number of options for working with data. We can store data  locally as JSON or CSV files, but these are relatively \"inert\". They have to be read into Python or some other system to make convenient searches, for example. Through a database, you have consistent storage that many people can access and you can use the computational engine  to filter, group and compute on data before you bring it into Python, say. So while your  data may be humongous, your interest might be in individual people. There is no need to hold gigabytes of data in memory when you only need a small plart.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "         .--.             .---.\n",
    "        /:.  '.         .' ..  '._.---.\n",
    "       /:::-.  \\.-\"\"\"-;` .-:::.     .::\\\n",
    "      /::'|  `\\/  _ _  \\'   `\\:'   ::::|\n",
    "  __.'    |   /  (o|o)  \\     `'.   ':/\n",
    " /    .:. /   |   ___   |        '---'\n",
    "|    ::::'   /:  (._.) .:\\\n",
    "\\    .='    |:'        :::|\n",
    " `\"\"`       \\     .-.   ':/\n",
    "       jgs   '---`|I|`---'\n",
    "                  '-'\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "\n",
    "After we installed mongo, we access the mongo shell simply by typing: `mongo`\n",
    "\n",
    "Since we set up some access restrictions (i.e. username + password login) for our Mongo, you'll have to type the following if you want to access the mongo shell:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`mongo tweets -u journalist -p secret`\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-- or --\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`mongo tweets -u journalist`\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ^^ this version will prompt you for your password\n",
    "\n",
    "If you need to log in to the database as the \"admin\" user, you can simply do:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`mongo -u admin`\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Remember: we set the admin password above"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
