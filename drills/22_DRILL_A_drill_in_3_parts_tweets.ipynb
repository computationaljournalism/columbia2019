{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. The madding crowd\n",
    "\n",
    "<img src='https://media1.s-nbcnews.com/j/newscms/2019_16/2761146/190221-mueller-report-live-blog-main-kh_7d773c19c99bc6c4c7ebafe761809094.fit-760w.jpg'>\n",
    "\n",
    "Now, let's have a look at Twitter and how the Mueller Report spread across the network. We collected tweets from just before 11am to just around 11:20am. Around 84,000 of them. This drill will help you load the tweets in to a pandas DataFrame and start to look at what the crowd is talking about as the report is dropped.\n",
    "\n",
    "To refresh your memory on the timeline of events for April 18:\n",
    "- [Barr](https://en.wikipedia.org/wiki/William_Barr) holds a [press conference](https://www.nytimes.com/2019/04/18/us/politics/barr-conference-transcript.html)\n",
    " at 9:30 am ET to discuss the report.\n",
    "- Around 11am, the Mueller Report is made available for download ([pdf](https://www.justice.gov/storage/report.pdf))\n",
    "\n",
    "Before Monday's class, run through the following notebook which will help you load the Tweets into a DataFrame. Have a look at the Tweets and come to class on Monday sharing something you found. Some ideas of what you might look at:\n",
    "- what is the discussion / what are they saying about the report?\n",
    "- who do the tweets mention?\n",
    "- what's the first mention of the report dropping? when was it?\n",
    "- who is tweeting during this time window?\n",
    "- what media outlets are covering the report? how long after the report drops are news outlets publishing stories about it?\n",
    "- any bot activity?\n",
    "\n",
    "Remember, use some of our new skills we learned on Wednesday (i.e. spacy) to look through the tweets. You might start with using spacy to look at the entities of the tweets: which people, places, locations, organizations are being mentioned. Take a look...have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Data\n",
    "To get started, [download the tweets from github](\n",
    "https://www.dropbox.com/s/1u53sw3v74ra2u8/mueller_tweets.jsonl.gz?dl=0) and put it in the same folder as your notebook.\n",
    "\n",
    "The file is about 67Megs (it's compressed) and contains 83,478 tweets. The file was compressed using a program called [gzip](https://en.wikipedia.org/wiki/Gzip). Uncompressed it's about 500-600Megs. Let's leave it compressed so we don't take up half-a-gig on your laptop hard-drive!\n",
    "\n",
    "The file itself is in a format called \"json lines\" - the file extension being `.jsonl`. Each line of the file contains a single tweet (as a json string) followed by a newline (`\\n`).\n",
    "\n",
    "We can use the command line to peek af the first few lines of the file. We'll run the `gunzip` command to uncompress the file (but we'll use the `-c` option which means we'll uncompress the file during out command but leave the file on the hard-drive as compressed). So, let's look at the first line of the file with some of our old UNIX commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -c mueller_tweets.jsonl.gz | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have printed out a single tweet. If this didn't work for you (prob on a Windows laptop?), then don't worry about it. Let's move on!\n",
    "\n",
    "The following file will open up the tweets data file and extract some of the fields from each tweet that we want to use later on in our analysis. I'm pulling out a few fields like the tweet, retweet/fave counts and a bit of info about the user. Feel free to edit to pull other info you might want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "# we'll save a subset of each tweet in a list that we'll then load into a DataFrame later\n",
    "tweets = []\n",
    "\n",
    "# gzip (compressed) file of 83478 tweets\n",
    "# for the format of the file: each line is a tweet (as a JSON string) followed by a newline ('\\n')\n",
    "# the .jsonl means \"json lines\"\n",
    "mueller_tweets_file = 'mueller_tweets.jsonl.gz'\n",
    "\n",
    "# open the gzip file\n",
    "with gzip.open(mueller_tweets_file) as tweets_file:\n",
    "    \n",
    "    # loop through the file, line-by-line\n",
    "    for line in tweets_file:\n",
    "        \n",
    "        # load the tweet in to a dictionary\n",
    "        tweet = json.loads(line)\n",
    "\n",
    "        # lets save a few things from each tweet:\n",
    "        # \"created at\" time\n",
    "        # the tweet id \"string\"\n",
    "        # retweet and fave counts\n",
    "        # the tweet text itself\n",
    "        # the user's screen name\n",
    "        # the user's follower + following counts\n",
    "        # how many tweets the user tweeted in the past\n",
    "        \n",
    "        user = tweet['user']\n",
    "        \n",
    "        # save a list of the tweet and user info we want for analysis\n",
    "        tweets.append(\n",
    "            [\n",
    "                tweet['created_at'],\n",
    "                tweet['id_str'],\n",
    "                tweet['favorite_count'],\n",
    "                tweet['retweet_count'],\n",
    "                tweet['text'],\n",
    "                user['screen_name'], \n",
    "                user['followers_count'],\n",
    "                user['friends_count'],\n",
    "                user['statuses_count'],\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "print('done loading the tweets from our file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tweets do we have?\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets is a list of lists. let's print out the first few rows and take a look\n",
    "tweets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tweets in to a DataFrame\n",
    "columns = ['created_at', 'id', 'favorite_count', 'retweet_count', 'text', 'screen_name', 'followers_count', 'friends_count', 'statuses_count']\n",
    "\n",
    "tweets_df = pd.DataFrame(tweets, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we saw in class on Wednesday, we convert the created_at column (which is a string) into a proper datetime object\n",
    "from pandas import to_datetime\n",
    "\n",
    "# convert the date as a string into a datetime object and store it in a new column named \"time\"\n",
    "tweets_df['time'] = to_datetime(tweets_df['created_at'].astype(str), format='%a %b %d %H:%M:%S +0000 %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the tweets per minute and see if it looks like the tweet per minute chart we created in part 1 (in class on Wednesday). To do this, we need to group our new 'time' column and create a count of tweets which occur every minute. We do that this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's group the tweets by minute\n",
    "counts = tweets_df.groupby(pd.Grouper(key='time', freq='60s')).agg({'id': 'count'}).rename(columns={'id': 'count'})\n",
    "counts.reset_index(inplace=True)\n",
    "\n",
    "# counts is now a DataFrame with time (each minute in from 14:56 GMT to 15:21 GMT) and the count of tweets per minute\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's abuse Mark's plotly account again and do a quick plot of time (by each minute) on the X-axis and the count of tweets per minute on the Y-axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.plotly import iplot, sign_in\n",
    "from plotly.graph_objs import Scatter, Figure\n",
    "\n",
    "# sign into the service (get your own credentials!)\n",
    "sign_in(\"cocteautt\",\"8YLww0QuMPVQ46meAMaq\")\n",
    "\n",
    "# create a plot of a single line tracking tweets over time\n",
    "myplot_parts = [Scatter(x=counts[\"time\"],y=counts[\"count\"],mode=\"line\")]\n",
    "\n",
    "# make a figure from this line plot...\n",
    "myfigure = Figure(data=myplot_parts)\n",
    "\n",
    "# ... and plot it (the filename is a convention plotly needs in case you want to use it later)\n",
    "iplot(myfigure,filename=\"tweets_per_min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this look like the plot we did at the end of class on Wednesday? Even though the count of tweets per minute won't be exact as the data we looked at on Wednesday, it is directionaly aligned. (The counts not matching up exactly is [documented on Twitter's API site](https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search.html), but don't worry about it for now.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it's your turn!** Remember, the report has just dropped and your tasked with looking at the public and media coverage and reaction. What's being said? Who is Twitter talking about? What media outlets are starting to cover it?\n",
    "\n",
    "Take a look over the weekend. Make sure you run through the notebook and we'll continue from here on Monday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
